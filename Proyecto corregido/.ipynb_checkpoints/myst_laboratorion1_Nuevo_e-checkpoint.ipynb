{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto para laboratorio 1: Administración activa Vs Administración pasiva del capital.\n",
    "\n",
    "<img src=\"https://www.google.com/search?q=iteso+imagenes&sxsrf=ACYBGNRuniJ0XQ3HCBjfq9sHJdF2JP0eAA:1568326542761&source=lnms&tbm=isch&sa=X&ved=0ahUKEwjnjuTTp8zkAhVSgK0KHT5VD-8Q_AUIEigB&biw=1280&bih=612#imgrc=_\">\n",
    "\n",
    "\n",
    "\n",
    "## Equipo E\n",
    "\n",
    "### Integrantes:\n",
    "\n",
    "Ana Paula Rangel Ochoa\n",
    "\n",
    "Paulina Rodriguez Guerrero\n",
    "\n",
    "José Luis Suárez de Alba\n",
    "\n",
    "Diego Velasco Sanchez\n",
    "\n",
    "\n",
    "\n",
    "### Situación:\n",
    "\n",
    "<div class=text-justify>  \n",
    "Acabas de entrar a trabajar a una operadora de fondos de inversión como analista financiero dentro de la mesa de análisis del mercado de renta variable. En la junta trimestral se plantea la posibilidad de crear un fondo propio con exposición al mercado de valores de USA tratando de replicar a los ETFs conocidos como ishares que la empresa BlackRock ofrece.\n",
    "\n",
    "   La idea es replicar un ETF con posiciones en directo. Te han asignado la tarea de hacer un ejercicio simple de replicar la construcción de un portafolio de inversión y un criterio de rebalanceo lo más parecido a un ETF de ishares que tu selecciones. Esto con la finalidad de comparar los resultados de haber rebanceado periódicamente el portafolio, ó, no haberlo hecho y continuar todo un año con las mismas posiciones.\n",
    "   \n",
    "</div>\n",
    "    \n",
    "### Caracteristicas:\n",
    "\n",
    "<div class=text-justify> \n",
    "   Debido a tu formación, te piden que este proceso que construyas sea repetible para cualquier ETF y también incluir 3 medidas de atribución al desempeño, tanto para el caso que el ETF nunca hubiese sido rebalanceado como para los casos donde sí.\n",
    "\n",
    "   En la mesa de análisis están interesados en conocer el proceso que sigues para adquirir, limpiar, dar formato y utilizar los datos, y a pesar que el equipo senior de análisis está compuesto por personal altamente calificado en temas de economía y finanzas, ellos no saben programar por lo que te piden que incluyas el código utilizado, y que sea de manera ordenada y explicando el sentido de las funciones y paqueterías que requeriste.\n",
    "   \n",
    "   * Comparar con 1 año de información: 1.3.17 al 1.3.18.\n",
    "\n",
    "   * Utilizar un ETF de Ishares para el mercado de renta varialbe de USA.\n",
    "\n",
    "   * Entregar un Jupyter Notebook con explicación y comentarios en el código.\n",
    "\n",
    "   * Crear y actualizar continuamente un repositorio en GitHub para el proyecto.\n",
    "</div>\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "https://www.quandl.com/search?filters=%5B%22Mutual%20Funds%20%26%20ETFs%22%2C%22Free%22%2C%22United%20States%22%5D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETF \n",
    "https://www.ishares.com/us/products/239770/\n",
    "\n",
    "<div class=text-justify> \n",
    "Obtener los rendimientos mensuales sacar la desviación estándar para tener la volatilidad de esta es diaria entonces es la desviación de los rendimientos diarios tenemos 12 meses, pero no se modifican ni el primero ni el ultimo con el peso calculamos la varianza desviación de cada mes usando la desviación de los diarios\n",
    "</div>\n",
    "<div class=text-justify> \n",
    "1.\tDescargar los datos mensuales de un año.\n",
    "2.\tRendimientos diarios y la desv estandar y el sharp (tasa libre de riesgo usa, treasury hold).\n",
    "3.\tNet asset value diario es l NAV (el precio diario de tu ETF) este sirve para sacar la volatilidad y ver si hubo picos si no hay está muy tranquilo (rendimientos diarios por los pesos mensuales para sacar el diario) --> de los 13 archivos.\n",
    "4.\tHacer 11 escenarios diferentes para ver cual habría sido la mejor situación.\n",
    "</div>\n",
    "Escenarios\n",
    " * Todo el año con los primeros pesos.\n",
    " * Rebalancear igual que el ETF.\n",
    " * Rebalancear cada mes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xlrd\n",
    "#pip install xlwt\n",
    "#pip install quandl\n",
    "import quandl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de mis archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listo\n"
     ]
    }
   ],
   "source": [
    "#extraccion de los 13 meses archivos\n",
    "mes1    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes1.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes1.dropna()\n",
    "\n",
    "mes2    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes2.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes2.dropna()\n",
    "mes3    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes3.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes3.dropna()\n",
    "mes4    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes4.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes4.dropna()\n",
    "mes5    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes5.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes5.dropna()\n",
    "mes6    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes6.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9])\n",
    "mes6.dropna()\n",
    "mes7    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes7.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes7.dropna()\n",
    "mes8    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes8.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes8.dropna()\n",
    "mes9    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes9.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9])\n",
    "mes9.dropna()\n",
    "mes10    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes10.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9])\n",
    "mes10.dropna()\n",
    "mes11    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes11.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes11.dropna()\n",
    "mes12    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes12.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes12.dropna()\n",
    "mes13    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes13.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9])\n",
    "mes13.dropna()\n",
    "\n",
    "print(\"listo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraer Shares Outstanding de los archivos\n",
    "so1= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes1.csv') \n",
    "so2= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes2.csv')\n",
    "so3= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes3.csv')\n",
    "so4= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes4.csv')\n",
    "so5= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes5.csv')\n",
    "so6= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes6.csv')\n",
    "so7= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes7.csv')\n",
    "so8= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes8.csv')\n",
    "so9= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes9.csv')\n",
    "so10= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes10.csv')\n",
    "so11= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes11.csv')\n",
    "so12= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes12.csv')\n",
    "so13= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes13.csv')\n",
    "\n",
    "so1=so1.iloc[3,1]\n",
    "so2=so2.iloc[3,1]\n",
    "so3=so3.iloc[3,1]\n",
    "so4=so4.iloc[3,1]\n",
    "so5=so5.iloc[3,1]\n",
    "so6=so6.iloc[3,1]\n",
    "so7=so7.iloc[3,1]\n",
    "so8=so8.iloc[3,1]\n",
    "so9=so9.iloc[3,1]\n",
    "so10=so10.iloc[3,1]\n",
    "so11=so11.iloc[3,1]\n",
    "so12=so12.iloc[3,1]\n",
    "so13=so13.iloc[3,1]\n",
    "\n",
    "#quitar comas\n",
    "so1=so1.replace(',', '')\n",
    "so1=so1.replace('', '')\n",
    "so2=so2.replace(',', '')\n",
    "so3=so3.replace(',', '')\n",
    "so4=so4.replace(',', '')\n",
    "so5=so5.replace(',', '')\n",
    "so6=so6.replace(',', '')\n",
    "so7=so7.replace(',', '')\n",
    "so8=so8.replace(',', '')\n",
    "so9=so9.replace(',', '')\n",
    "so10=so10.replace(',', '')\n",
    "so11=so11.replace(',', '')\n",
    "so12=so12.replace(',', '')\n",
    "so13=so13.replace(',', '')\n",
    "\n",
    "so1=float(so1)\n",
    "so2=float(so2)\n",
    "so3=float(so3)\n",
    "so4=float(so4)\n",
    "so5=float(so5)\n",
    "so6=float(so6)\n",
    "so7=float(so7)\n",
    "so8=float(so8)\n",
    "so9=float(so9)\n",
    "so10=float(so10)\n",
    "so11=float(so11)\n",
    "so12=float(so12)\n",
    "so13=float(so13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separo mis tickers, precios y numero de acciones por mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmes1   = mes1['Ticker'] #tickets primer mes\n",
    "price1  = mes1['Price'] #precios primer mes\n",
    "shares1  = mes1['Shares'] #shares primer mes\n",
    "\n",
    "xmes2   = mes2['Ticker'] \n",
    "price2  = mes2['Price'] \n",
    "shares2  = mes2['Shares'] \n",
    "\n",
    "xmes3   = mes3['Ticker'] \n",
    "price3  = mes3['Price'] \n",
    "shares3  = mes3['Shares']\n",
    "\n",
    "xmes4   = mes4['Ticker'] \n",
    "price4  = mes4['Price'] \n",
    "shares4  = mes4['Shares']\n",
    "\n",
    "xmes5   = mes5['Ticker'] \n",
    "price5  = mes5['Price'] \n",
    "shares5  = mes5['Shares']\n",
    "\n",
    "xmes6   = mes6['Ticker'] \n",
    "price6  = mes6['Price'] \n",
    "shares6  = mes6['Shares']\n",
    "\n",
    "xmes7   = mes7['Ticker'] \n",
    "price7  = mes7['Price'] \n",
    "shares7  = mes7['Shares']\n",
    "\n",
    "xmes8   = mes8['Ticker'] \n",
    "price8  = mes8['Price'] \n",
    "shares8  = mes8['Shares']\n",
    "\n",
    "xmes9   = mes9['Ticker'] \n",
    "price9  = mes9['Price'] \n",
    "shares9  = mes9['Shares']\n",
    "\n",
    "\n",
    "xmes10   = mes10['Ticker'] \n",
    "price10  = mes10['Price'] \n",
    "shares10  = mes10['Shares']\n",
    "\n",
    "xmes11   = mes11['Ticker'] \n",
    "price11  = mes11['Price'] \n",
    "shares11  = mes11['Shares']\n",
    "\n",
    "xmes12   = mes12['Ticker'] \n",
    "price12  = mes12['Price'] \n",
    "shares12  = mes12['Shares']\n",
    "\n",
    "xmes13   = mes13['Ticker'] \n",
    "price13  = mes13['Price'] \n",
    "shares13  = mes13['Shares']\n",
    "\n",
    "print(\"listo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplicamos el precio de cada accion por el respectivo numero de accciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares1=mes1['Shares'].dropna()\n",
    "s1=[]\n",
    "for i in shares1:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s1.append(Temp)\n",
    "    \n",
    "p1=mes1['Price'].dropna()\n",
    "c1=np.dot(s1,p1) #Precios del mes 1 por el numero de acciones del mes 1\n",
    "\n",
    "shares2=mes2['Shares'].dropna()\n",
    "s2=[]\n",
    "for i in shares2:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s2.append(Temp)\n",
    "    \n",
    "p2=mes2['Price'].dropna()\n",
    "\n",
    "c2=np.dot(s2,p2)\n",
    "\n",
    "shares3=mes3['Shares'].dropna()\n",
    "s3=[]\n",
    "for i in shares3:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s3.append(Temp)\n",
    "    \n",
    "p3=mes3['Price'].dropna()\n",
    "\n",
    "c3=np.dot(s3,p3)\n",
    "\n",
    "shares4=mes4['Shares'].dropna()\n",
    "s4=[]\n",
    "for i in shares4:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s4.append(Temp)\n",
    "    \n",
    "p4=mes4['Price'].dropna()\n",
    "\n",
    "c4=np.dot(s4,p4)\n",
    "\n",
    "shares5=mes5['Shares'].dropna()\n",
    "s5=[]\n",
    "for i in shares5:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s5.append(Temp)\n",
    "    \n",
    "p5=mes5['Price'].dropna()\n",
    "\n",
    "c5=np.dot(s5,p5)\n",
    "\n",
    "shares6=mes6['Shares'].dropna()\n",
    "s6=[]\n",
    "for i in shares6:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s6.append(Temp)\n",
    "    \n",
    "p6=mes6['Price'].dropna()\n",
    "\n",
    "c6=np.dot(s6,p6)\n",
    "\n",
    "shares7=mes7['Shares'].dropna()\n",
    "s7=[]\n",
    "for i in shares7:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s7.append(Temp)\n",
    "    \n",
    "p7=mes7['Price'].dropna()\n",
    "\n",
    "c7=np.dot(s7,p7)\n",
    "\n",
    "shares8=mes8['Shares'].dropna()\n",
    "s8=[]\n",
    "for i in shares8:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s8.append(Temp)\n",
    "    \n",
    "p8=mes8['Price'].dropna()\n",
    "\n",
    "c8=np.dot(s8,p8)\n",
    "\n",
    "shares9=mes9['Shares'].dropna()\n",
    "s9=[]\n",
    "for i in shares9:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s9.append(Temp)\n",
    "    \n",
    "p9=mes9['Price'].dropna()\n",
    "\n",
    "c9=np.dot(s9,p9)\n",
    "\n",
    "shares10=mes10['Shares'].dropna()\n",
    "s10=[]\n",
    "for i in shares10:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s10.append(Temp)\n",
    "    \n",
    "p10=mes10['Price'].dropna()\n",
    "\n",
    "c10=np.dot(s10,p10)\n",
    "\n",
    "shares11=mes11['Shares'].dropna()\n",
    "s11=[]\n",
    "for i in shares11:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s11.append(Temp)\n",
    "    \n",
    "p11=mes11['Price'].dropna()\n",
    "\n",
    "c11=np.dot(s11,p11)\n",
    "\n",
    "shares12=mes12['Shares'].dropna()\n",
    "s12=[]\n",
    "for i in shares12:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s12.append(Temp)\n",
    "    \n",
    "p12=mes12['Price'].dropna()\n",
    "\n",
    "c12=np.dot(s12,p12)\n",
    "\n",
    "shares13=mes13['Shares'].dropna()\n",
    "s13=[]\n",
    "for i in shares13:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s13.append(Temp)\n",
    "    \n",
    "p13=mes13['Price'].dropna()\n",
    "\n",
    "c13=np.dot(s13,p13)\n",
    "\n",
    "print(\"listo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NAV mensual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav1=c1/so1\n",
    "nav2=c2/so2\n",
    "nav3=c3/so3\n",
    "nav4=c4/so4\n",
    "nav5=c5/so5\n",
    "nav6=c6/so6\n",
    "nav7=c7/so7\n",
    "nav8=c8/so8\n",
    "nav9=c9/so9\n",
    "nav10=c10/so10\n",
    "nav11=c11/so11\n",
    "nav12=c12/so12\n",
    "nav13=c13/so13\n",
    "\n",
    "navs=[nav1,nav2,nav3,nav4,nav5,nav6,nav7,nav8,nav9,nav10,nav11,nav12,nav13]\n",
    "navs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendimientos mensuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rend(x,y):\n",
    "    return (x/y)-1\n",
    "\n",
    "rend1=rend(nav2,nav1)\n",
    "rend2=rend(nav3,nav2)\n",
    "rend3=rend(nav4,nav3)\n",
    "rend4=rend(nav5,nav4)\n",
    "rend5=rend(nav6,nav5)\n",
    "rend6=rend(nav7,nav6)\n",
    "rend7=rend(nav8,nav7)\n",
    "rend8=rend(nav9,nav8)\n",
    "rend9=rend(nav10,nav9)\n",
    "rend10=rend(nav11,nav10)\n",
    "rend11=rend(nav12,nav11)\n",
    "rend12=rend(nav13,nav12)\n",
    "\n",
    "rends=[rend1,rend2,rend3,rend4,rend5,rend6,rend7,rend8,rend9,rend10,rend11,rend12]\n",
    "Month=[1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "#rends=pd.DataFrame(rends)\n",
    "#rends.rename(index={-1:'Month'}, columns={0:'Rend'}, inplace=True)\n",
    "#rends\n",
    "\n",
    "d=pd.DataFrame(list(zip(Month,rends)), columns=[\"Month\",\"Rend\"])\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tickers unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#union de los tickers unicos de los 13 archivos\n",
    "smes=set(xmes1)|set(xmes2)|set(xmes3)|set(xmes4)|set(xmes5)|set(xmes6)|set(xmes7)|set(xmes8)|set(xmes9)|set(xmes10)|set(xmes11)|set(xmes12)|set(xmes13)\n",
    "len(smes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraer datos de quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quandl.ApiConfig.api_key = \"wzJyeSB_seJSjER5FGSA\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_quandl = quandl.get_table('WIKI/PRICES', ticker = [smes], qopts = {'columns': ['ticker', 'date', 'close']},\n",
    "                        date = {'gte': '2017-02-28', 'lte': '2018-02-28'}, paginate=True)\n",
    "d_quandl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = d_quandl.set_index('date')\n",
    "daily_data = daily_data.pivot(columns='ticker')\n",
    "daily_data.dropna()\n",
    "datos=daily_data.T\n",
    "datos.rename(index={0:'Date'}, columns={1:'SM'}, inplace=True)\n",
    "datos.index\n",
    "p=datos.reset_index(level=[0,1])\n",
    "p = p.fillna(0)\n",
    "p.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_prices = d_quandl.set_index('date')\n",
    "historic_prices = historic_prices.pivot(columns='ticker')\n",
    "historic_prices.columns = historic_prices.columns.droplevel(0)\n",
    "historic_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A continuación hacemos 12 tablas con las acciones de cada mes y sus respectivos precios diarios y pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares1\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m1=list(xmes1)\n",
    "sh1=list(s1)\n",
    "junto=[m1,sh1]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x1s      = pd.merge(xx,ss,on='ticker')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares2\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m2=list(xmes2)\n",
    "sh2=list(s2)\n",
    "junto=[m2,sh2]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x2s      = pd.merge(xx,ss,on='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares3\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m3=list(xmes3)\n",
    "sh3=list(s3)\n",
    "junto=[m3,sh3]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x3s      = pd.merge(xx,ss,on='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares4\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m4=list(xmes4)\n",
    "sh4=list(s4)\n",
    "junto=[m4,sh4]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x4s      = pd.merge(xx,ss,on='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares5\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m5=list(xmes5)\n",
    "sh5=list(s5)\n",
    "junto=[m5,sh5]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x5s      = pd.merge(xx,ss,on='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares6\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m6=list(xmes6)\n",
    "sh6=list(s6)\n",
    "junto=[m6,sh6]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x6s      = pd.merge(xx,ss,on='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares7\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m7=list(xmes7)\n",
    "sh7=list(s7)\n",
    "junto=[m7,sh7]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x7s      = pd.merge(xx,ss,on='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares8\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m8=list(xmes8)\n",
    "sh8=list(s8)\n",
    "junto=[m8,sh8]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x8s      = pd.merge(xx,ss,on='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares9\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m9=list(xmes9)\n",
    "sh9=list(s9)\n",
    "junto=[m9,sh9]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x9s      = pd.merge(xx,ss,on='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares10\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m10=list(xmes10)\n",
    "sh10=list(s10)\n",
    "junto=[m10,sh10]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x10s      = pd.merge(xx,ss,on='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares11\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m11=list(xmes11)\n",
    "sh11=list(s11)\n",
    "junto=[m11,sh11]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x11s      = pd.merge(xx,ss,on='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares12\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m12=list(xmes12)\n",
    "sh12=list(s12)\n",
    "junto=[m12,sh12]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x12s      = pd.merge(xx,ss,on='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlookup a shares13\n",
    "tickers_quandl=p['ticker']#base de quandl de 22\n",
    "xx=pd.DataFrame(tickers_quandl)\n",
    "m13=list(xmes13)\n",
    "sh13=list(s13)\n",
    "junto=[m13,sh13]#union ticker y shares\n",
    "ss=pd.DataFrame(junto).T\n",
    "ss.columns=['ticker','shares']\n",
    "\n",
    "x13s      = pd.merge(xx,ss,on='ticker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se separan los datos de quandl en meses para nuestras 12 tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crean las fechas con la librería datetime\n",
    "b=historic_prices\n",
    "fecha_1 = dt.datetime(2017, 2, 28)\n",
    "fecha_2 = dt.datetime(2017, 3, 28)\n",
    "fecha_3 = dt.datetime(2017, 4, 28)\n",
    "fecha_4 = dt.datetime(2017, 5, 30)\n",
    "fecha_5 = dt.datetime(2017, 6, 28)\n",
    "fecha_6 = dt.datetime(2017, 7, 28)\n",
    "fecha_7 = dt.datetime(2017, 8, 28)\n",
    "fecha_8 = dt.datetime(2017, 9, 28)\n",
    "fecha_9 = dt.datetime(2017, 10, 30)\n",
    "fecha_10 = dt.datetime(2017, 11, 28)\n",
    "fecha_11 = dt.datetime(2017, 12, 28)\n",
    "fecha_12 = dt.datetime(2018, 1, 29)\n",
    "fecha_13 = dt.datetime(2018, 2, 28)\n",
    "# Filtro por fecha\n",
    "b1=b.loc[fecha_1: fecha_2]\n",
    "b2=b.loc[fecha_2:fecha_3]\n",
    "b3=b.loc[fecha_3:fecha_4]\n",
    "b4=b.loc[fecha_4:fecha_5]\n",
    "b5=b.loc[fecha_5:fecha_6]\n",
    "b6=b.loc[fecha_6:fecha_7]\n",
    "b7=b.loc[fecha_7:fecha_8]\n",
    "b8=b.loc[fecha_8:fecha_9]\n",
    "b9=b.loc[fecha_9:fecha_10]\n",
    "b10=b.loc[fecha_10:fecha_11]\n",
    "b11=b.loc[fecha_11:fecha_12]\n",
    "b12=b.loc[fecha_12:fecha_13]\n",
    "#SE VUELVE A TRANSPONER\n",
    "m1q=b1.T\n",
    "m2q=b2.T\n",
    "m3q=b3.T\n",
    "m4q=b4.T\n",
    "m5q=b5.T\n",
    "m6q=b6.T\n",
    "m7q=b7.T\n",
    "m8q=b8.T\n",
    "m9q=b9.T\n",
    "m10q=b10.T\n",
    "m11q=b11.T\n",
    "m12q=b12.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Acontinuacion nos quedan las 12 tablas, en donde se podnran encontrar los tickers mensuales con sus precios diarios, se sacara el nav diario y su desviación estandar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraccion de datos diarios en quandl en base a tickers del mes\n",
    "ts1=list(x1s['ticker'])\n",
    "t1=m1q.iloc[[(ticker in ts1) for ticker in b1.iloc[:0]]]\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=x1s[\"shares\"]\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm1=np.std(nav1)\n",
    "desm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraccion de datos diarios en quandl en base a tickers del mes\n",
    "ts2=list(x2s['ticker'])\n",
    "t2=m2q.iloc[[(ticker in ts2) for ticker in b2.iloc[:0]]]\n",
    "t2=t2.reset_index(level=[0,0])\n",
    "tt2=t2.iloc[:,1:]\n",
    "sh2=x2s[\"shares\"]\n",
    "tab2=tt2.mul(sh2,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab2.columns)):\n",
    "    z=sum(tab2.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ2=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ2.columns)):\n",
    "    x=(summ2.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav2=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm2=np.std(nav2)\n",
    "desm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraccion de datos diarios en quandl en base a tickers del mes\n",
    "ts3=list(x3s['ticker'])\n",
    "t3=m3q.iloc[[(ticker in ts3) for ticker in b3.iloc[:0]]]\n",
    "t3=t3.reset_index(level=[0,0])\n",
    "tt3=t3.iloc[:,3:]\n",
    "sh3=x3s[\"shares\"]\n",
    "tab3=tt3.mul(sh3,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab3.columns)):\n",
    "    z=sum(tab3.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ3=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ3.columns)):\n",
    "    x=(summ3.iloc[:,i])/so3\n",
    "    nav.append(x)\n",
    "nav3=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm3=np.std(nav3)\n",
    "desm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraccion de datos diarios en quandl en base a tickers del mes\n",
    "ts4=list(x4s['ticker'])\n",
    "t4=m4q.iloc[[(ticker in ts4) for ticker in b4.iloc[:0]]]\n",
    "t4=t4.reset_index(level=[0,0])\n",
    "tt4=t4.iloc[:,4:]\n",
    "sh4=x4s[\"shares\"]\n",
    "tab4=tt4.mul(sh4,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab4.columns)):\n",
    "    z=sum(tab4.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ4=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ4.columns)):\n",
    "    x=(summ4.iloc[:,i])/so4\n",
    "    nav.append(x)\n",
    "nav4=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm4=np.std(nav4)\n",
    "desm4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraccion de datos diarios en quandl en base a tickers del mes\n",
    "ts5=list(x5s['ticker'])\n",
    "t5=m5q.iloc[[(ticker in ts5) for ticker in b5.iloc[:0]]]\n",
    "t5=t5.reset_index(level=[0,0])\n",
    "tt5=t5.iloc[:,5:]\n",
    "sh5=x5s[\"shares\"]\n",
    "tab5=tt5.mul(sh5,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab5.columns)):\n",
    "    z=sum(tab5.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ5=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ5.columns)):\n",
    "    x=(summ5.iloc[:,i])/so5\n",
    "    nav.append(x)\n",
    "nav5=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm5=np.std(nav5)\n",
    "desm5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraccion de datos diarios en quandl en base a tickers del mes\n",
    "ts6=list(x6s['ticker'])\n",
    "t6=m6q.iloc[[(ticker in ts6) for ticker in b6.iloc[:0]]]\n",
    "t6=t6.reset_index(level=[0,0])\n",
    "tt6=t6.iloc[:,6:]\n",
    "sh6=x6s[\"shares\"]\n",
    "tab6=tt6.mul(sh6,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab6.columns)):\n",
    "    z=sum(tab6.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ6=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ6.columns)):\n",
    "    x=(summ6.iloc[:,i])/so6\n",
    "    nav.append(x)\n",
    "nav6=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm6=np.std(nav6)\n",
    "desm6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraccion de datos diarios en quandl en base a tickers del mes\n",
    "ts7=list(x7s['ticker'])\n",
    "t7=m7q.iloc[[(ticker in ts7) for ticker in b7.iloc[:0]]]\n",
    "t7=t7.reset_index(level=[0,0])\n",
    "tt7=t7.iloc[:,7:]\n",
    "sh7=x7s[\"shares\"]\n",
    "tab7=tt7.mul(sh7,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab7.columns)):\n",
    "    z=sum(tab7.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ7=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ7.columns)):\n",
    "    x=(summ7.iloc[:,i])/so7\n",
    "    nav.append(x)\n",
    "nav7=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm7=np.std(nav7)\n",
    "desm7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraccion de datos diarios en quandl en base a tickers del mes\n",
    "ts8=list(x8s['ticker'])\n",
    "t8=m8q.iloc[[(ticker in ts8) for ticker in b8.iloc[:0]]]\n",
    "t8=t8.reset_index(level=[0,0])\n",
    "tt8=t8.iloc[:,8:]\n",
    "sh8=x8s[\"shares\"]\n",
    "tab8=tt8.mul(sh8,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab8.columns)):\n",
    "    z=sum(tab8.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ8=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ8.columns)):\n",
    "    x=(summ8.iloc[:,i])/so8\n",
    "    nav.append(x)\n",
    "nav8=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm8=np.std(nav8)\n",
    "desm8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraccion de datos diarios en quandl en base a tickers del mes\n",
    "ts9=list(x9s['ticker'])\n",
    "t9=m9q.iloc[[(ticker in ts9) for ticker in b9.iloc[:0]]]\n",
    "t9=t9.reset_index(level=[0,0])\n",
    "tt9=t9.iloc[:,9:]\n",
    "sh9=x9s[\"shares\"]\n",
    "tab9=tt9.mul(sh9,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab9.columns)):\n",
    "    z=sum(tab9.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ9=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ9.columns)):\n",
    "    x=(summ9.iloc[:,i])/so9\n",
    "    nav.append(x)\n",
    "nav9=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm9=np.std(nav9)\n",
    "desm9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraccion de datos diarios en quandl en base a tickers del mes\n",
    "ts10=list(x10s['ticker'])\n",
    "t10=m10q.iloc[[(ticker in ts10) for ticker in b10.iloc[:0]]]\n",
    "t10=t10.reset_index(level=[0,0])\n",
    "tt10=t10.iloc[:,10:]\n",
    "sh10=x10s[\"shares\"]\n",
    "tab10=tt10.mul(sh10,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab10.columns)):\n",
    "    z=sum(tab10.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ10=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ10.columns)):\n",
    "    x=(summ10.iloc[:,i])/so10\n",
    "    nav.append(x)\n",
    "nav10=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm10=np.std(nav10)\n",
    "desm10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraccion de datos diarios en quandl en base a tickers del mes\n",
    "ts11=list(x11s['ticker'])\n",
    "t11=m11q.iloc[[(ticker in ts11) for ticker in b11.iloc[:0]]]\n",
    "t11=t11.reset_index(level=[0,0])\n",
    "tt11=t11.iloc[:,11:]\n",
    "sh11=x11s[\"shares\"]\n",
    "tab11=tt11.mul(sh11,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab11.columns)):\n",
    "    z=sum(tab11.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ11=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ11.columns)):\n",
    "    x=(summ11.iloc[:,i])/so11\n",
    "    nav.append(x)\n",
    "nav11=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm11=np.std(nav11)\n",
    "desm11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraccion de datos diarios en quandl en base a tickers del mes\n",
    "ts12=list(x12s['ticker'])\n",
    "t12=m12q.iloc[[(ticker in ts12) for ticker in b12.iloc[:0]]]\n",
    "t12=t12.reset_index(level=[0,0])\n",
    "tt12=t12.iloc[:,12:]\n",
    "sh12=x12s[\"shares\"]\n",
    "tab12=tt12.mul(sh12,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab12.columns)):\n",
    "    z=sum(tab12.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ12=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ12.columns)):\n",
    "    x=(summ12.iloc[:,i])/so12\n",
    "    nav.append(x)\n",
    "nav12=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm12=np.std(nav12)\n",
    "desm12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasas ( Treasury Yield )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para sacar el rendimiento del mercado\n",
    "treasury = pd.read_excel('Treasury Yield.xlsx', header = 0) \n",
    "t_y=[0.75,0.68,0.77,0.89,1,0.99,0.97,0.97,1.16,2.39,1.28,1.5]\n",
    "desv=[desm1,desm2,desm3,desm4,desm5,desm6,desm7,desm7,desm8,desm9,desm10,desm11,desm12]\n",
    "rends=[rend1,rend2,rend3,rend4,rend5,rend6,rend7,rend8,rend9,rend10,rend11,rend12]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PORTAFOLIO REAL MENSUAL DEL ETF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sacar Sharpe\n",
    "from operator import truediv \n",
    "\n",
    "t_y=[0.0075,0.0068,0.0077,0.0089,0.001,0.0099,0.0097,0.0097,0.0116,0.0039,0.0128,0.015]\n",
    "desv=[desm1,desm2,desm3,desm4,desm5,desm6,desm7,desm7,desm8,desm9,desm10,desm11,desm12]\n",
    "rends=[rend1,rend2,rend3,rend4,rend5,rend6,rend7,rend8,rend9,rend10,rend11,rend12]\n",
    "\n",
    "\n",
    "r=list(np.array(rends)-np.array(t_y))\n",
    "sharpe=[i/j for i, j in zip(r,desv)]\n",
    "sharpe\n",
    "#sharpe=(rends-t_y)/desv\n",
    "#sharpe\n",
    "sharpe=np.array(sharpe)\n",
    "\n",
    "d=pd.DataFrame(list(zip(Month,rends,desv,sharpe)), columns=[\"Month\",\"Rend\",\"D.Std\",\"Sharpe\"])\n",
    "\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(lst): \n",
    "    return sum(lst) / len(lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrr=average(rends)*12\n",
    "ddd=average(desv)\n",
    "sss=average(sharpe)*12\n",
    "\n",
    "print(\"rendimiento anual ETF: \", rrr)\n",
    "print( \"desviacion anual ETF: \",ddd)\n",
    "print( \"sharepe anual ETF1: \",sss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESCENARIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCENARIO 1: SE CORRE CON EL MES 1 EL RESTO DEL AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1=list(x1s['ticker'])\n",
    "datat=b.T\n",
    "t1=datat.iloc[[(ticker in ts1) for ticker in b.iloc[:]]]\n",
    "t1 = t1.fillna(0)\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=x1s[\"shares\"]\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "desm1=np.std(nav1)\n",
    "navprimero=nav1.iloc[0]\n",
    "navultimo=nav1.iloc[-1]\n",
    "rend_esc1=rend(navultimo,navprimero)\n",
    "t_y=0.0075\n",
    "sh=( rend_esc1-t_y)/desm1\n",
    "\n",
    "print(\"rendimiento escenario1: \", rend_esc1)\n",
    "print( \"desviacion escenario 1: \",desm1)\n",
    "print( \"Sharpe escenario 1: \", sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCENARIO 2: SE CORRE DESDE EL MES 2 EL RESTO DEL AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u2=[b2,b3,b4,b5,b6,b7,b8,b9,b10,b11,b12]\n",
    "d2=pd.concat(u2)\n",
    "d2=d2.T\n",
    "ts1=list(x2s['ticker'])\n",
    "t1=d2.iloc[[(ticker in ts1) for ticker in b.iloc[:]]]\n",
    "t1 = t1.fillna(0)\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=x2s[\"shares\"]\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "std2=np.std(nav1)\n",
    "navprimero=nav1.iloc[0]\n",
    "navultimo=nav1.iloc[-1]\n",
    "rend_esc2=rend(navultimo,navprimero)\n",
    "r2m=rend1*(1/12)\n",
    "d2m=desm1*(1/12)\n",
    "s2m=sharpe[0]*(1/12)\n",
    "re2=rend_esc2\n",
    "std2=std2\n",
    "#sumamos ponderaciones\n",
    "r2=r2m+re2\n",
    "st2=d2m+std2\n",
    "\n",
    "t_y=0.0068\n",
    "sh=(r2-t_y)/st2\n",
    "\n",
    "\n",
    "\n",
    "print(\"rendimiento escenario2: \",r2 )\n",
    "print( \"desviacion escenario 2: \",st2 )\n",
    "print( \"Sharpe escenario 2: \", sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCENARIO 3: SE CORRE DESDE EL MES 3 EL RESTO DEL AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u3=[b3,b4,b5,b6,b7,b8,b9,b10,b11,b12]\n",
    "d3=pd.concat(u3)\n",
    "d3=d3.T\n",
    "ts1=list(x3s['ticker'])\n",
    "t1=d3.iloc[[(ticker in ts1) for ticker in b.iloc[:]]]\n",
    "t1 = t1.fillna(0)\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=x3s[\"shares\"]\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "std3=np.std(nav1)\n",
    "navprimero=nav1.iloc[0]\n",
    "navultimo=nav1.iloc[-1]\n",
    "rend_esc3=rend(navultimo,navprimero)\n",
    "r3m1=rend1*(1/12)\n",
    "d3m1=desm1*(1/12)\n",
    "s3m=sharpe[0]*(1/12)\n",
    "r3m2=rend2*(1/12)\n",
    "d3m2=desm2*(1/12)\n",
    "re3=rend_esc3\n",
    "std3=std3\n",
    "#sumamos ponderaciones\n",
    "r3=r3m1+r3m2+re3\n",
    "st3=d3m1+d3m2+std3\n",
    "\n",
    "t_y=0.0077\n",
    "sh=( r3-t_y)/st3\n",
    "\n",
    "print(\"rendimiento escenario1: \",r3 )\n",
    "print( \"desviacion escenario 1: \",st3 )\n",
    "print( \"sharp escenario 1: \",sh )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCENARIO 4: SE CORRE DESDE EL MES 4 EL RESTO DEL AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u4=[b4,b5,b6,b7,b8,b9,b10,b11,b12]\n",
    "d4=pd.concat(u4)\n",
    "d4=d4.T\n",
    "ts1=list(x4s['ticker'])\n",
    "t1=d4.iloc[[(ticker in ts1) for ticker in b.iloc[:]]]\n",
    "t1 = t1.fillna(0)\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=x4s[\"shares\"]\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "std4=np.std(nav1)\n",
    "navprimero=nav1.iloc[0]\n",
    "navultimo=nav1.iloc[-1]\n",
    "rend_esc4=rend(navultimo,navprimero)\n",
    "r4m1=rend1*(1/12)\n",
    "d4m1=desm1*(1/12)\n",
    "s4m=sharpe[0]*(1/12)\n",
    "r4m2=rend2*(1/12)\n",
    "d4m2=desm2*(1/12)\n",
    "r4m3=rend3*(1/12)\n",
    "d4m3=desm3*(1/12)\n",
    "\n",
    "re4=rend_esc4\n",
    "std4=std4\n",
    "#sumamos ponderaciones\n",
    "r4=r4m1+r4m2+r4m3+re4\n",
    "st4=d4m1+d4m2+d4m3+std4\n",
    "\n",
    "t_y=0.0089\n",
    "sh=( r4-t_y)/st4\n",
    "\n",
    "\n",
    "print(\"rendimiento escenario1: \",r4 )\n",
    "print( \"desviacion escenario 1: \",st4 )\n",
    "print( \"sharpe escenario 1: \",sh )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCENARIO 5: SE CORRE DESDE EL MES 5 EL RESTO DEL AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u5=[b5,b6,b7,b8,b9,b10,b11,b12]\n",
    "d5=pd.concat(u5)\n",
    "d5=d5.T\n",
    "ts1=list(x5s['ticker'])\n",
    "t1=d5.iloc[[(ticker in ts1) for ticker in b.iloc[:]]]\n",
    "t1 = t1.fillna(0)\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=x5s[\"shares\"]\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "std5=np.std(nav1)\n",
    "navprimero=nav1.iloc[0]\n",
    "navultimo=nav1.iloc[-1]\n",
    "rend_esc5=rend(navultimo,navprimero)\n",
    "r5m1=rend1*(1/12)\n",
    "d5m1=desm1*(1/12)\n",
    "s5m=sharpe[0]*(1/12)\n",
    "r5m2=rend2*(1/12)\n",
    "d5m2=desm2*(1/12)\n",
    "r5m3=rend3*(1/12)\n",
    "d5m3=desm3*(1/12)\n",
    "r5m4=rend4*(1/12)\n",
    "d5m4=desm4*(1/12)\n",
    "\n",
    "re5=rend_esc5\n",
    "std5=std5\n",
    "#sumamos ponderaciones\n",
    "r5=r5m1+r5m2+r5m3+r5m4+re5\n",
    "st5=d5m1+d5m2+d5m3+d5m4+std5\n",
    "\n",
    "\n",
    "t_y=0.001\n",
    "sh=( r5-t_y)/st5\n",
    "\n",
    "print(\"rendimiento escenario1: \",r5 )\n",
    "print( \"desviacion escenario 1: \",st5 )\n",
    "print( \"sharpe escenario 1: \",sh )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCENARIO 6: SE CORRE DESDE EL MES 6 EL RESTO DEL AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u6=[b6,b7,b8,b9,b10,b11,b12]\n",
    "d6=pd.concat(u6)\n",
    "d6=d6.T\n",
    "ts1=list(x6s['ticker'])\n",
    "t1=d6.iloc[[(ticker in ts1) for ticker in b.iloc[:]]]\n",
    "t1 = t1.fillna(0)\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=x6s[\"shares\"]\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "std6=np.std(nav1)\n",
    "navprimero=nav1.iloc[0]\n",
    "navultimo=nav1.iloc[-1]\n",
    "rend_esc6=rend(navultimo,navprimero)\n",
    "r6m1=rend1*(1/12)\n",
    "d6m1=desm1*(1/12)\n",
    "s6m=sharpe[0]*(1/12)\n",
    "r6m2=rend2*(1/12)\n",
    "d6m2=desm2*(1/12)\n",
    "r6m3=rend3*(1/12)\n",
    "d6m3=desm3*(1/12)\n",
    "r6m4=rend4*(1/12)\n",
    "d6m4=desm4*(1/12)\n",
    "r6m5=rend5*(1/12)\n",
    "d6m5=desm5*(1/12)\n",
    "\n",
    "re6=rend_esc6\n",
    "std6=std6\n",
    "#sumamos ponderaciones\n",
    "r6=r6m1+r6m2+r6m3+r6m4+r6m5+re6\n",
    "st6=d6m1+d6m2+d6m3+d6m4+d6m5+std6\n",
    "\n",
    "\n",
    "t_y=0.0099\n",
    "sh=( r6-t_y)/st6\n",
    "\n",
    "print(\"rendimiento escenario1: \",r6 )\n",
    "print( \"desviacion escenario 1: \",st6 )\n",
    "print( \"sharpe escenario 1: \",sh )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCENARIO 7: SE CORRE DESDE EL MES 7 EL RESTO DEL AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u7=[b7,b8,b9,b10,b11,b12]\n",
    "d7=pd.concat(u7)\n",
    "d7=d7.T\n",
    "ts1=list(x7s['ticker'])\n",
    "t1=d7.iloc[[(ticker in ts1) for ticker in b.iloc[:]]]\n",
    "t1 = t1.fillna(0)\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=x7s[\"shares\"]\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "std7=np.std(nav1)\n",
    "navprimero=nav1.iloc[0]\n",
    "navultimo=nav1.iloc[-1]\n",
    "rend_esc7=rend(navultimo,navprimero)\n",
    "r7m1=rend1*(1/12)\n",
    "d7m1=desm1*(1/12)\n",
    "s7m=sharpe[0]*(1/12)\n",
    "r7m2=rend2*(1/12)\n",
    "d7m2=desm2*(1/12)\n",
    "r7m3=rend3*(1/12)\n",
    "d7m3=desm3*(1/12)\n",
    "r7m4=rend4*(1/12)\n",
    "d7m4=desm4*(1/12)\n",
    "r7m5=rend5*(1/12)\n",
    "d7m5=desm5*(1/12)\n",
    "r7m6=rend6*(1/12)\n",
    "d7m6=desm6*(1/12)\n",
    "\n",
    "re7=rend_esc7\n",
    "std7=std7\n",
    "#sumamos ponderaciones\n",
    "r7=r7m1+r7m2+r7m3+r7m4+r7m5+r7m6+re7\n",
    "st7=d7m1+d7m2+d7m3+d7m4+d7m5+d7m6+std7\n",
    "\n",
    "\n",
    "t_y=0.0097\n",
    "sh=( r7-t_y)/st7\n",
    "\n",
    "print(\"rendimiento escenario1: \",r7 )\n",
    "print( \"desviacion escenario 1: \",st7 )\n",
    "print( \"sharpe escenario 1: \",sh )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCENARIO 8: SE CORRE DESDE EL MES 8 EL RESTO DEL AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u8=[b8,b8,b9,b10,b11,b12]\n",
    "d8=pd.concat(u8)\n",
    "d8=d8.T\n",
    "ts1=list(x8s['ticker'])\n",
    "t1=d8.iloc[[(ticker in ts1) for ticker in b.iloc[:]]]\n",
    "t1 = t1.fillna(0)\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=x8s[\"shares\"]\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "std8=np.std(nav1)\n",
    "navprimero=nav1.iloc[0]\n",
    "navultimo=nav1.iloc[-1]\n",
    "rend_esc8=rend(navultimo,navprimero)\n",
    "r8m1=rend1*(1/12)\n",
    "d8m1=desm1*(1/12)\n",
    "s8m=sharpe[0]*(1/12)\n",
    "r8m2=rend2*(1/12)\n",
    "d8m2=desm2*(1/12)\n",
    "r8m3=rend3*(1/12)\n",
    "d8m3=desm3*(1/12)\n",
    "r8m4=rend4*(1/12)\n",
    "d8m4=desm4*(1/12)\n",
    "r8m5=rend5*(1/12)\n",
    "d8m5=desm5*(1/12)\n",
    "r8m6=rend6*(1/12)\n",
    "d8m6=desm6*(1/12)\n",
    "r8m7=rend7*(1/12)\n",
    "d8m7=desm7*(1/12)\n",
    "\n",
    "re8=rend_esc8\n",
    "std8=\n",
    "#sumamos ponderaciones\n",
    "r8=r8m1+r8m2+r8m3+r8m4+r8m5+r8m6+r8m7+re8\n",
    "st8=d8m1+d8m2+d8m3+d8m4+d8m5+d8m6+d8m7+std8\n",
    "\n",
    "\n",
    "t_y=0.0097\n",
    "sh=( r8-t_y)/st8\n",
    "\n",
    "print(\"rendimiento escenario1: \",r8 )\n",
    "print( \"desviacion escenario 1: \",st8 )\n",
    "print( \"sharpe escenario 1: \",sh )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCENARIO 9: SE CORRE DESDE EL MES 9 EL RESTO DEL AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u9=[b8,b9,b10,b11,b12]\n",
    "d9=pd.concat(u9)\n",
    "d9=d9.T\n",
    "ts1=list(x9s['ticker'])\n",
    "t1=d9.iloc[[(ticker in ts1) for ticker in b.iloc[:]]]\n",
    "t1 = t1.fillna(0)\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=x9s[\"shares\"]\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "std9=np.std(nav1)\n",
    "navprimero=nav1.iloc[0]\n",
    "navultimo=nav1.iloc[-1]\n",
    "rend_esc9=rend(navultimo,navprimero)\n",
    "r9m1=rend1*(1/12)\n",
    "d9m1=desm1*(1/12)\n",
    "s9m=sharpe[0]*(1/12)\n",
    "r9m2=rend2*(1/12)\n",
    "d9m2=desm2*(1/12)\n",
    "r9m3=rend3*(1/12)\n",
    "d9m3=desm3*(1/12)\n",
    "r9m4=rend4*(1/12)\n",
    "d9m4=desm4*(1/12)\n",
    "r9m5=rend5*(1/12)\n",
    "d9m5=desm5*(1/12)\n",
    "r9m6=rend6*(1/12)\n",
    "d9m6=desm6*(1/12)\n",
    "r9m7=rend7*(1/12)\n",
    "d9m7=desm7*(1/12)\n",
    "r9m8=rend8*(1/12)\n",
    "d9m8=desm8*(1/12)\n",
    "\n",
    "re9=rend_esc9\n",
    "std9=std9\n",
    "#sumamos ponderaciones\n",
    "r9=r9m1+r9m2+r9m3+r9m4+r9m5+r9m6+r9m7+r9m8+re9\n",
    "st9=d9m1+d9m2+d9m3+d9m4+d9m5+d9m6+d9m7+d9m8+std9\n",
    "\n",
    "\n",
    "t_y=0.0116\n",
    "sh=( r9-t_y)/st9\n",
    "\n",
    "print(\"rendimiento escenario1: \",r9 )\n",
    "print( \"desviacion escenario 1: \",st9 )\n",
    "print( \"sharpe escenario 1: \",sh )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCENARIO 10: SE CORRE DESDE EL MES 10 EL RESTO DEL AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u10=[b9,b10,b11,b12]\n",
    "d10=pd.concat(u10)\n",
    "d10=d10.T\n",
    "ts1=list(x10s['ticker'])\n",
    "t1=d10.iloc[[(ticker in ts1) for ticker in b.iloc[:]]]\n",
    "t1 = t1.fillna(0)\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=x10s[\"shares\"]\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "std10=np.std(nav1)\n",
    "navprimero=nav1.iloc[0]\n",
    "navultimo=nav1.iloc[-1]\n",
    "rend_esc10=rend(navultimo,navprimero)\n",
    "r10m1=rend1*(1/12)\n",
    "d10m1=desm1*(1/12)\n",
    "s10m=sharpe[0]*(1/12)\n",
    "r10m2=rend2*(1/12)\n",
    "d10m2=desm2*(1/12)\n",
    "r10m3=rend3*(1/12)\n",
    "d10m3=desm3*(1/12)\n",
    "r10m4=rend4*(1/12)\n",
    "d10m4=desm4*(1/12)\n",
    "r10m5=rend5*(1/12)\n",
    "d10m5=desm5*(1/12)\n",
    "r10m6=rend6*(1/12)\n",
    "d10m6=desm6*(1/12)\n",
    "r10m7=rend7*(1/12)\n",
    "d10m7=desm7*(1/12)\n",
    "r10m8=rend8*(1/12)\n",
    "d10m8=desm8*(1/12)\n",
    "r10m9=rend9*(1/12)\n",
    "d10m9=desm9*(1/12)\n",
    "\n",
    "re10=rend_esc10\n",
    "std10=std10\n",
    "#sumamos ponderaciones\n",
    "r10=r10m1+r10m2+r10m3+r10m4+r10m5+r10m6+r10m7+r10m8+r10m9+re10\n",
    "st10=d10m1+d10m2+d10m3+d10m4+d10m5+d10m6+d10m7+d10m8+d10m9+std10\n",
    "\n",
    "\n",
    "t_y=0.0039\n",
    "sh=( r10-t_y)/st10\n",
    "\n",
    "print(\"rendimiento escenario1: \",r10 )\n",
    "\n",
    "print( \"desviacion escenario 1: \",st10 )\n",
    "print( \"sharpe escenario 1: \",sh )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCENARIO 11: SE CORRE DESDE EL MES 11 EL RESTO DEL AÑO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u11=[b10,b11,b12]\n",
    "d11=pd.concat(u11)\n",
    "d11=d11.T\n",
    "ts1=list(x11s['ticker'])\n",
    "t1=d11.iloc[[(ticker in ts1) for ticker in b.iloc[:]]]\n",
    "t1 = t1.fillna(0)\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=x11s[\"shares\"]\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/so1\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "std11=np.std(nav1)\n",
    "navprimero=nav1.iloc[0]\n",
    "navultimo=nav1.iloc[-1]\n",
    "rend_esc11=rend(navultimo,navprimero)\n",
    "r11m1=rend1*(1/12)\n",
    "d11m1=desm1*(1/12)\n",
    "s11m=sharpe[0]*(1/12)\n",
    "r11m2=rend2*(1/12)\n",
    "d11m2=desm2*(1/12)\n",
    "r11m3=rend3*(1/12)\n",
    "d11m3=desm3*(1/12)\n",
    "r11m4=rend4*(1/12)\n",
    "d11m4=desm4*(1/12)\n",
    "r11m5=rend5*(1/12)\n",
    "d11m5=desm5*(1/12)\n",
    "r11m6=rend6*(1/12)\n",
    "d11m6=desm6*(1/12)\n",
    "r11m7=rend7*(1/12)\n",
    "d11m7=desm7*(1/12)\n",
    "r11m8=rend8*(1/12)\n",
    "d11m8=desm8*(1/12)\n",
    "r11m9=rend9*(1/12)\n",
    "d11m9=desm9*(1/12)\n",
    "r11m10=rend10*(1/12)\n",
    "d11m10=desm10*(1/12)\n",
    "\n",
    "re11=rend_esc11\n",
    "std11=std11\n",
    "#sumamos ponderaciones\n",
    "r11=r11m1+r11m2+r11m3+r11m4+r11m5+r11m6+r11m7+r11m8+r11m9+r11m10+re11\n",
    "st11=d11m1+d11m2+d11m3+d11m4+d11m5+d11m6+d11m7+d11m8+d11m9+r11m10+std11\n",
    "\n",
    "\n",
    "t_y=0.015\n",
    "sh=( r11-t_y)/st11\n",
    "\n",
    "print(\"rendimiento escenario1: \",r11 )\n",
    "print( \"desviacion escenario 1: \",st11 )\n",
    "print( \"sharpe escenario 1: \",sh )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REBALANCEO PROPUESTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Tenemos un presupuesto de 600,000 USD.\n",
    "Analizando las acciones decidimos invertit en MSI, CSCO, CIEN, IDCC, PLT, EXTR durante todo el año.\n",
    "Invertiremos el capital proporcional a las 6\n",
    "Hay 1,600,000 acciones en circulación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]\n",
    "acc=[\"MSI\",\"CSCO\",\"CIEN\",\"IDCC\",\"PLT\",\"EXTR\"]\n",
    "#a=pd.DataFrame(acc)\n",
    "prop=pd.DataFrame(list(zip(n,acc)), columns=[\"num\",\"ticker\"])\n",
    "\n",
    "\n",
    "capital=600000\n",
    "w=[100000,100000,100000,100000,100000,100000]\n",
    "SO=160000000\n",
    "\n",
    "\n",
    "ts1=list(prop['ticker'])\n",
    "datat=b.T\n",
    "t1=datat.iloc[[(ticker in ts1) for ticker in b.iloc[:]]]\n",
    "t1 = t1.fillna(0)\n",
    "t1=t1.reset_index(level=[0,0])\n",
    "tt1=t1.iloc[:,1:]\n",
    "sh1=w\n",
    "tab1=tt1.mul(sh1,axis=0)\n",
    "\n",
    "#ciclo para la suma de columnas\n",
    "sumas=[]\n",
    "for i in range(len(tab1.columns)):\n",
    "    z=sum(tab1.iloc[:,i])\n",
    "    sumas.append(z)\n",
    "summ1=pd.DataFrame(sumas).T\n",
    "\n",
    "#ciclo para division entre SO\n",
    "nav=[]\n",
    "for i in range(len(summ1.columns)):\n",
    "    x=(summ1.iloc[:,i])/SO\n",
    "    nav.append(x)\n",
    "nav1=pd.DataFrame(nav)\n",
    "#desvicion de navs\n",
    "stdd=np.std(nav1)\n",
    "navprimero=nav1.iloc[0]\n",
    "navultimo=nav1.iloc[-1]\n",
    "rend_esc1=rend(navultimo,navprimero)\n",
    "t_y=0.0075\n",
    "\n",
    "sh=(rend_esc1-t_y)/stdd\n",
    "\n",
    "print(\"rendimiento revalanceo: \", rend_esc1)\n",
    "print( \"desviacion revalanceo: \",stdd)\n",
    "print( \"Sharpe revalanceo: \", sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión \n",
    "\n",
    "La desviacion estamdar es muy importante para conocer la volatilidad y el riesgo del portafolio, ya que depende del perfil (adverso al riesgo o no adverso al riesgo)del inversionista con esta medida puede darse cuenta si el portafolio es apto o no apto para el.\n",
    "\n",
    "Podemos notar que en la propuesta nuestro rendimiento es de un 9.8% y nuestra volatilidad es del 0.8% lo cual indica que es un portafolio que casi no tiene riesgo, por lo que sería ideal para las personas aversas al riesgo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
