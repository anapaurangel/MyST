{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto para laboratorio 1: Administración activa Vs Administración pasiva del capital.\n",
    "\n",
    "<img src=\"https://www.google.com/search?q=iteso+imagenes&sxsrf=ACYBGNRuniJ0XQ3HCBjfq9sHJdF2JP0eAA:1568326542761&source=lnms&tbm=isch&sa=X&ved=0ahUKEwjnjuTTp8zkAhVSgK0KHT5VD-8Q_AUIEigB&biw=1280&bih=612#imgrc=_\">\n",
    "\n",
    "\n",
    "\n",
    "## Equipo E\n",
    "\n",
    "### Integrantes:\n",
    "\n",
    "Ana Paula Rangel Ochoa\n",
    "\n",
    "Paulina Rodriguez Guerrero\n",
    "\n",
    "José Luis Suárez de Alba\n",
    "\n",
    "Diego Velasco Sanchez\n",
    "\n",
    "\n",
    "\n",
    "### Situación:\n",
    "\n",
    "<div class=text-justify>  \n",
    "Acabas de entrar a trabajar a una operadora de fondos de inversión como analista financiero dentro de la mesa de análisis del mercado de renta variable. En la junta trimestral se plantea la posibilidad de crear un fondo propio con exposición al mercado de valores de USA tratando de replicar a los ETFs conocidos como ishares que la empresa BlackRock ofrece.\n",
    "\n",
    "   La idea es replicar un ETF con posiciones en directo. Te han asignado la tarea de hacer un ejercicio simple de replicar la construcción de un portafolio de inversión y un criterio de rebalanceo lo más parecido a un ETF de ishares que tu selecciones. Esto con la finalidad de comparar los resultados de haber rebanceado periódicamente el portafolio, ó, no haberlo hecho y continuar todo un año con las mismas posiciones.\n",
    "   \n",
    "</div>\n",
    "    \n",
    "### Caracteristicas:\n",
    "\n",
    "<div class=text-justify> \n",
    "   Debido a tu formación, te piden que este proceso que construyas sea repetible para cualquier ETF y también incluir 3 medidas de atribución al desempeño, tanto para el caso que el ETF nunca hubiese sido rebalanceado como para los casos donde sí.\n",
    "\n",
    "   En la mesa de análisis están interesados en conocer el proceso que sigues para adquirir, limpiar, dar formato y utilizar los datos, y a pesar que el equipo senior de análisis está compuesto por personal altamente calificado en temas de economía y finanzas, ellos no saben programar por lo que te piden que incluyas el código utilizado, y que sea de manera ordenada y explicando el sentido de las funciones y paqueterías que requeriste.\n",
    "   \n",
    "   * Comparar con 1 año de información: 1.3.17 al 1.3.18.\n",
    "\n",
    "   * Utilizar un ETF de Ishares para el mercado de renta varialbe de USA.\n",
    "\n",
    "   * Entregar un Jupyter Notebook con explicación y comentarios en el código.\n",
    "\n",
    "   * Crear y actualizar continuamente un repositorio en GitHub para el proyecto.\n",
    "</div>\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "https://www.quandl.com/search?filters=%5B%22Mutual%20Funds%20%26%20ETFs%22%2C%22Free%22%2C%22United%20States%22%5D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETF \n",
    "https://www.ishares.com/us/products/239770/\n",
    "\n",
    "<div class=text-justify> \n",
    "Obtener los rendimientos mensuales sacar la desviación estándar para tener la volatilidad de esta es diaria entonces es la desviación de los rendimientos diarios tenemos 12 meses, pero no se modifican ni el primero ni el ultimo con el peso calculamos la varianza desviación de cada mes usando la desviación de los diarios\n",
    "</div>\n",
    "<div class=text-justify> \n",
    "1.\tDescargar los datos mensuales de un año.\n",
    "2.\tRendimientos diarios y la desv estandar y el sharp (tasa libre de riesgo usa, treasury hold).\n",
    "3.\tNet asset value diario es l NAV (el precio diario de tu ETF) este sirve para sacar la volatilidad y ver si hubo picos si no hay está muy tranquilo (rendimientos diarios por los pesos mensuales para sacar el diario) --> de los 13 archivos.\n",
    "4.\tHacer 11 escenarios diferentes para ver cual habría sido la mejor situación.\n",
    "</div>\n",
    "Escenarios\n",
    " * Todo el año con los primeros pesos.\n",
    " * Rebalancear igual que el ETF.\n",
    " * Rebalancear cada mes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xlrd\n",
    "#pip install xlwt\n",
    "#pip install quandl\n",
    "import quandl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Información general del ETF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de mis archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listo\n"
     ]
    }
   ],
   "source": [
    "#extraccion de los 13 meses archivos\n",
    "mes1    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes1.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes1.dropna()\n",
    "\n",
    "mes2    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes2.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes2.dropna()\n",
    "mes3    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes3.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes3.dropna()\n",
    "mes4    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes4.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes4.dropna()\n",
    "mes5    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes5.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes5.dropna()\n",
    "mes6    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes6.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9])\n",
    "mes6.dropna()\n",
    "mes7    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes7.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes7.dropna()\n",
    "mes8    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes8.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes8.dropna()\n",
    "mes9    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes9.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9])\n",
    "mes9.dropna()\n",
    "mes10    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes10.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9])\n",
    "mes10.dropna()\n",
    "mes11    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes11.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes11.dropna()\n",
    "mes12    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes12.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9]) \n",
    "mes12.dropna()\n",
    "mes13    = pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes13.csv',\n",
    "                   skiprows = [0,1,2,3,4,5,6,7,8,9])\n",
    "mes13.dropna()\n",
    "\n",
    "print(\"listo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 2 fields in line 11, saw 16\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-7c7ec202b0a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mso1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mso2\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes2.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mso3\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes3.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mso4\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes4.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mso5\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes5.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ana\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ana\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ana\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ana\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 11, saw 16\n"
     ]
    }
   ],
   "source": [
    "#extraer Shares Outstanding de los archivos\n",
    "so1= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes1.csv')\n",
    "so2= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes2.csv')\n",
    "so3= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes3.csv')\n",
    "so4= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes4.csv')\n",
    "so5= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes5.csv')\n",
    "so6= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes6.csv')\n",
    "so7= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes7.csv')\n",
    "so8= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes8.csv')\n",
    "so9= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes9.csv')\n",
    "so10= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes10.csv')\n",
    "so11= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes11.csv')\n",
    "so12= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes12.csv')\n",
    "so13= pd.read_csv('https://raw.githubusercontent.com/anapaurangel/MyST/master/Proyecto%20corregido/mes13.csv')\n",
    "\n",
    "so1=so1.iloc[2,1]\n",
    "so2=so2.iloc[2,1]\n",
    "so3=so3.iloc[2,1]\n",
    "so4=so4.iloc[2,1]\n",
    "so5=so5.iloc[2,1]\n",
    "so6=so6.iloc[2,1]\n",
    "so7=so7.iloc[2,1]\n",
    "so8=so8.iloc[2,1]\n",
    "so9=so9.iloc[2,1]\n",
    "so10=so10.iloc[2,1]\n",
    "so11=so11.iloc[2,1]\n",
    "so12=so12.iloc[2,1]\n",
    "so13=so13.iloc[2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separo mis tickers, precios y numero de acciones por mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listo\n"
     ]
    }
   ],
   "source": [
    "xmes1   = mes1['Ticker'] #tickets primer mes\n",
    "price1  = mes1['Price'] #precios primer mes\n",
    "shares1  = mes1['Shares'] #shares primer mes\n",
    "\n",
    "xmes2   = mes2['Ticker'] \n",
    "price2  = mes2['Price'] \n",
    "shares2  = mes2['Shares'] \n",
    "\n",
    "xmes3   = mes3['Ticker'] \n",
    "price3  = mes3['Price'] \n",
    "shares3  = mes3['Shares']\n",
    "\n",
    "xmes4   = mes4['Ticker'] \n",
    "price4  = mes4['Price'] \n",
    "shares4  = mes4['Shares']\n",
    "\n",
    "xmes5   = mes5['Ticker'] \n",
    "price5  = mes5['Price'] \n",
    "shares5  = mes5['Shares']\n",
    "\n",
    "xmes6   = mes6['Ticker'] \n",
    "price6  = mes6['Price'] \n",
    "shares6  = mes6['Shares']\n",
    "\n",
    "xmes7   = mes7['Ticker'] \n",
    "price7  = mes7['Price'] \n",
    "shares7  = mes7['Shares']\n",
    "\n",
    "xmes8   = mes8['Ticker'] \n",
    "price8  = mes8['Price'] \n",
    "shares8  = mes8['Shares']\n",
    "\n",
    "xmes9   = mes9['Ticker'] \n",
    "price9  = mes9['Price'] \n",
    "shares9  = mes9['Shares']\n",
    "\n",
    "\n",
    "xmes10   = mes10['Ticker'] \n",
    "price10  = mes10['Price'] \n",
    "shares10  = mes10['Shares']\n",
    "\n",
    "xmes11   = mes11['Ticker'] \n",
    "price11  = mes11['Price'] \n",
    "shares11  = mes11['Shares']\n",
    "\n",
    "xmes12   = mes12['Ticker'] \n",
    "price12  = mes12['Price'] \n",
    "shares12  = mes12['Shares']\n",
    "\n",
    "xmes13   = mes13['Ticker'] \n",
    "price13  = mes13['Price'] \n",
    "shares13  = mes13['Shares']\n",
    "\n",
    "print(\"listo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83447361.48"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares1=mes1['Shares'].dropna()\n",
    "s1=[]\n",
    "for i in shares1:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s1.append(Temp)\n",
    "    \n",
    "p1=mes1['Price'].dropna()\n",
    "\n",
    "c1=np.dot(s1,p1)\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79774490.4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares2=mes2['Shares'].dropna()\n",
    "s2=[]\n",
    "for i in shares2:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s2.append(Temp)\n",
    "    \n",
    "p2=mes2['Price'].dropna()\n",
    "\n",
    "c2=np.dot(s2,p2)\n",
    "c2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78429220.48999998"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares3=mes3['Shares'].dropna()\n",
    "s3=[]\n",
    "for i in shares3:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s3.append(Temp)\n",
    "    \n",
    "p3=mes3['Price'].dropna()\n",
    "\n",
    "c3=np.dot(s3,p3)\n",
    "c3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80015964.03999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares4=mes4['Shares'].dropna()\n",
    "s4=[]\n",
    "for i in shares4:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s4.append(Temp)\n",
    "    \n",
    "p4=mes4['Price'].dropna()\n",
    "\n",
    "c4=np.dot(s4,p4)\n",
    "c4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78721158.86999999"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares5=mes5['Shares'].dropna()\n",
    "s5=[]\n",
    "for i in shares5:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s5.append(Temp)\n",
    "    \n",
    "p5=mes5['Price'].dropna()\n",
    "\n",
    "c5=np.dot(s5,p5)\n",
    "c5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74867414.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares6=mes6['Shares'].dropna()\n",
    "s6=[]\n",
    "for i in shares6:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s6.append(Temp)\n",
    "    \n",
    "p6=mes6['Price'].dropna()\n",
    "\n",
    "c6=np.dot(s6,p6)\n",
    "c6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62081498.82"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares7=mes7['Shares'].dropna()\n",
    "s7=[]\n",
    "for i in shares7:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s7.append(Temp)\n",
    "    \n",
    "p7=mes7['Price'].dropna()\n",
    "\n",
    "c7=np.dot(s7,p7)\n",
    "c7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67050200.339999996"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares8=mes8['Shares'].dropna()\n",
    "s8=[]\n",
    "for i in shares8:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s8.append(Temp)\n",
    "    \n",
    "p8=mes8['Price'].dropna()\n",
    "\n",
    "c8=np.dot(s8,p8)\n",
    "c8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61684711.16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares9=mes9['Shares'].dropna()\n",
    "s9=[]\n",
    "for i in shares9:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s9.append(Temp)\n",
    "    \n",
    "p9=mes9['Price'].dropna()\n",
    "\n",
    "c9=np.dot(s9,p9)\n",
    "c9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54046404.66"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares10=mes10['Shares'].dropna()\n",
    "s10=[]\n",
    "for i in shares10:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s10.append(Temp)\n",
    "    \n",
    "p10=mes10['Price'].dropna()\n",
    "\n",
    "c10=np.dot(s10,p10)\n",
    "c10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52321786.60000001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares11=mes11['Shares'].dropna()\n",
    "s11=[]\n",
    "for i in shares11:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s11.append(Temp)\n",
    "    \n",
    "p11=mes11['Price'].dropna()\n",
    "\n",
    "c11=np.dot(s11,p11)\n",
    "c11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52759032.35"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares12=mes12['Shares'].dropna()\n",
    "s12=[]\n",
    "for i in shares12:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s12.append(Temp)\n",
    "    \n",
    "p12=mes12['Price'].dropna()\n",
    "\n",
    "c12=np.dot(s12,p12)\n",
    "c12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49924242.52"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares13=mes13['Shares'].dropna()\n",
    "s13=[]\n",
    "for i in shares13:\n",
    "    Temp=float(i.replace(\",\",\"\"))\n",
    "    s13.append(Temp)\n",
    "    \n",
    "p13=mes13['Price'].dropna()\n",
    "\n",
    "c13=np.dot(s13,p13)\n",
    "c13\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraer datos de quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quandl.ApiConfig.api_key = \"wzJyeSB_seJSjER5FGSA\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VSAT</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>68.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VSAT</td>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>70.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VSAT</td>\n",
       "      <td>2018-03-23</td>\n",
       "      <td>69.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VSAT</td>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>71.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VSAT</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>72.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker       date  close\n",
       "None                         \n",
       "0      VSAT 2018-03-27  68.30\n",
       "1      VSAT 2018-03-26  70.36\n",
       "2      VSAT 2018-03-23  69.13\n",
       "3      VSAT 2018-03-22  71.09\n",
       "4      VSAT 2018-03-21  72.17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_quandl = quandl.get_table('WIKI/PRICES', ticker = [tickers], qopts = {'columns': ['ticker', 'date', 'close']},\n",
    "                        date = {'gte': '2017-03-01', 'lte': '2018-04-01'}, paginate=True)\n",
    "d_quandl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-cca8cdd6a4a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdaily_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdaily_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdaily_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ticker'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdaily_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdatos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdaily_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdatos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'SM'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "daily_data = data.set_index('date')\n",
    "daily_data = daily_data.pivot(columns='ticker')\n",
    "daily_data.dropna()\n",
    "datos=daily_data.T\n",
    "datos.rename(index={0:'Date'}, columns={1:'SM'}, inplace=True)\n",
    "datos.index\n",
    "p=datos.reset_index(level=[0,1])\n",
    "p.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'set_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-094eeefda5c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistoric_prices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mhistoric_prices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistoric_prices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ticker'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhistoric_prices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'set_index'"
     ]
    }
   ],
   "source": [
    "historic_prices = data.set_index('date')\n",
    "historic_prices = historic_prices.pivot(columns='ticker')\n",
    "historic_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_prices.columns=test.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ana pau\n",
    "quandl.ApiConfig.api_key = 'wzJyeSB_seJSjER5FGSA'\n",
    "\n",
    "data = quandl.get_table('WIKI/PRICES', qopts = { 'columns': ['ticker', 'date', 'close'] }, \n",
    "                        ticker = [tickers], date = { 'gte': '2017-02-28', 'lte': '2018-02-28' })\n",
    "data (5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
